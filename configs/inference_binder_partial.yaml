data:
  task: binder_motif_partial # * hallucination, inpainting，binder, binder_rotamer, binder_motif
  dataset: ppi
  loader:
    num_workers: 0 # 4
    prefetch_factor: 10
  sampler:
    max_batch_size: 20
    max_num_res_squared: 350000
    batch_repeats: 2
interpolant:
  t_method: uniform   # * uniform, beta
  alpha_t: 3.0      # * beta distribution for noise level sampling
  min_t: 0.15 #partial
  max_t: 0.25 #partial
  separate_t: false
  provide_kappa: false
  hierarchical_t: false
  twisting:
    use: false
  starting_at_hotspot_center: false   # *
  rots:
    corrupt: true
    train_schedule: linear
    sample_schedule: exp
    exp_rate: 10
  trans:
    corrupt: true
    var_scale: 10        # *
    batch_ot: true
    train_schedule: linear
    sample_schedule: linear
    sample_temp: 1.0
    vpsde_bmin: 0.1
    vpsde_bmax: 20.0
    potential: null
    potential_t_scaling: false
    rog:
      weight: 10.0
      cutoff: 5.0
  sampling:
    num_timesteps: 100  # *
    do_sde: false
  self_condition: ${model.edge_features.self_condition}
folding:
  seq_per_sample: 8
  own_device: false
  folding_model: esmf
  pmpnn_path: ./ProteinMPNN/
  pt_hub_dir: ./.cache/torch/
experiment:
  debug: False #True, False
  novo_embedding_layers: false    # * 0328 motif
  seed: 123
  num_devices: 1     # * gpu num
  warm_start: null
  warm_start_cfg_override: false
  training:
    mask_plddt: true
    bb_atom_scale: 0.1
    trans_scale: 0.1
    translation_loss_weight: 2.0    # * originally 2.0,  3.0 is the normal scale
    t_normalize_clip: 0.9
    rotation_loss_weights: 1.0
    aux_loss_weight: 1.0          # * 1.0
    aux_loss_use_bb_loss: 1.0
    aux_loss_use_pair_loss: 1.0
    aux_loss_use_clash_loss: 0.0    # *
    aux_loss_use_interchain_clash_loss: 0.0   # *
    aux_loss_use_center_mse_loss: 0.0   # *
    aux_loss_use_interface_loss: 1.0  # **  1
    ca_clash_tolerance: 1.2
    interchain_clash_tolerance: 2.0
    aux_loss_t_pass: 0.5    # * 0.5
    pair_loss_use_hotspot_loss: false    # **
    trans_loss_clamp: 5 # #old:5
    auxiliary_loss_clamp: 5 # #old:5
    use_seq_loss: false     # *
    seq_loss_weight: 1.0   # *
    seq_loss_clamp: 5
  wandb:
    name: ${data.task}_${data.dataset}
    project: se3-fm
    save_code: true
    mode: offline
    save_dir: ${experiment.checkpointer.dirpath}/..
    dir: ${experiment.checkpointer.dirpath}/..
  optimizer:
    lr: 0.0001
  trainer:
    min_epochs: 1
    max_epochs: 1000 #1000 ，4 for debug
    accelerator: gpu
    log_every_n_steps: 1
    deterministic: false
    strategy: ddp #ddp:多机多卡， dp：单机多卡， #ddp_find_unused_parameters_true
    num_nodes: 1 #节点数
    check_val_every_n_epoch: 1  # *
    accumulate_grad_batches: 2  # * 2
    enable_progress_bar: True

  checkpointer:
    dirpath: results/${experiment.wandb.name}/${now:%Y%m%d}/${now:%H_%M_%S}/ckpt
#    save_last: True
    save_top_k: -1
    monitor: valid/non_coil_percent # valid/bb_rmsd
    mode: max # min
  pretrain_path: ../weights/pdb_amortization/published.ckpt # Modify it yourself

  testing_model: # **
    save_dir: sample_result/${experiment.wandb.name}/${now:%Y%m%d}/${now:%H_%M_%S}/sample_test
    ckpt_path:  "/lustre/grp/cmclab/share/guoly/ppiflow/ckpt/20250407_motif_v45_monomer_rcsb_from_mono_ep131/epoch=88-step=80367.ckpt"



shared:
  seed: 123
  max_cache_size: 100000
  samples_per_eval_length: 5
  num_eval_lengths: 8
  max_eval_length: 256
  min_motif_percent: 0.05
  max_motif_percent: 0.5

ppi_dataset:      # **
  seed: ${shared.seed}
#  test_csv_path:  /Users/linjie/projects/ppiflow-v1-scaffolding/complex_motif/testset/finish_pdb_rename_chain/testset7/test_metadata_local.csv
  test_csv_path: ../processed_complex_motif/train_metadata.csv
  define_hotspots: True  #used in sample, if True: use all target interface as hotspots; False: sample 3-len(target_interface)*20% as hotspots # ** #partial
  samples_min_hotspots: 3
  min_hotspot_ratio: 0.0
  max_hotspot_ratio: 0.2  # *
  motif:
    define_motif: False #used in sample, if True: use all motif ; False: sample 1~len(motif_list)-1 as motif # ** #partial

  max_cache_size: ${shared.max_cache_size}
  cache_num_res: 0
  add_plddt_mask: False
  max_eval_length: ${shared.max_eval_length}

  # Eval parameters
  samples_min_length: 50 # **
  samples_max_length: 100 # **
  samples_per_target: 5 # **
  samples_batch_size: 1 # **
  sample_original_binder_len: True # ** #partial
  scaffold_contig: null
  sample_pdbname: null


model:
  node_embed_size: 256
  edge_embed_size: 128
  symmetric: false
  # xk
  use_gradient_checkpointing: True   # *
  use_deepspeed_evo_attention: False   # *
  node_features:
    c_s: ${model.node_embed_size}
    c_pos_emb: 128
    c_timestep_emb: 128
    c_aatype_emb: 128
    max_num_res: 2000
    timestep_int: 1000
    embed_chain: true
    embed_aatype: true
    n_aatype: 22
  edge_features:
    single_bias_transition_n: 2
    c_s: ${model.node_embed_size}
    c_p: ${model.edge_embed_size}
    relpos_k: 64
    feat_dim: 64
    rel_pos_feat_dim: 64
    num_bins: 22
    self_condition: true
    embed_chain: true
    embed_diffuse_mask: true
    embed_hotspot_mask: true # True, False
  ipa:
    c_s: ${model.node_embed_size}
    c_z: ${model.edge_embed_size}
    c_hidden: 128
    no_heads: 8
    no_qk_points: 8
    no_v_points: 12
    seq_tfmr_num_heads: 4
    seq_tfmr_num_layers: 2
    num_blocks: 6
  seq_decoder:
    use: false    # *
    c_s: ${model.node_embed_size}
    feat_dim: 128
  pairformer:
    use: true
    c_s: ${model.node_embed_size}
    c_z: ${model.edge_embed_size}
    no_heads: 8
    num_blocks: 4   # *
    c_hidden_pair_att: 16
    no_heads_pair: 4
